{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 7d523dc5-aa11-46e9-8843-641df166ce2b\n",
      "Query executing: 0.76s\n",
      "Query complete after 1.08s\n"
     ]
    }
   ],
   "source": [
    "%%bigquery flights_df --project ml-course-test --verbose\n",
    "\n",
    "SELECT\n",
    "    departure_delay,\n",
    "    distance,\n",
    "    airline,\n",
    "    departure_airport,\n",
    "    arrival_airport,\n",
    "    CAST(EXTRACT(DAYOFWEEK FROM departure_date) AS STRING) departure_weekday,\n",
    "    CAST(EXTRACT(MONTH FROM departure_date) AS STRING) departure_month,\n",
    "    IF(arrival_delay >= 15, 1, 0) delayed\n",
    "FROM (\n",
    "    SELECT\n",
    "        departure_delay,\n",
    "        ROUND(ST_DISTANCE(\n",
    "            ST_GEOGPOINT(departure_lon, departure_lat),\n",
    "            ST_GEOGPOINT(arrival_lon, arrival_lat)\n",
    "        )/1000) distance,\n",
    "        airline,\n",
    "        arrival_airport,\n",
    "        departure_airport,\n",
    "        PARSE_DATE('%Y-%m-%d', date) departure_date,\n",
    "        arrival_delay\n",
    "    FROM `bigquery-samples.airline_ontime_data.flights`\n",
    "    WHERE\n",
    "        date >= '2009-01-01'\n",
    "        AND date <= '2009-12-31'\n",
    "        AND departure_delay > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe, labels='delayed', shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(labels)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(dataframe))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "# how many observations should be processed at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({departure_delay: (None,), distance: (None,), airline: (None,), departure_airport: (None,), arrival_airport: (None,), departure_weekday: (None,), departure_month: (None,)}, (None,)), types: ({departure_delay: tf.float64, distance: tf.float64, airline: tf.string, departure_airport: tf.string, arrival_airport: tf.string, departure_weekday: tf.string, departure_month: tf.string}, tf.int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "# sets default float type, e.g. 64, 32\n",
    "train_ds = dataframe_to_dataset(flights_df, batch_size=batch_size)\n",
    "test_ds = dataframe_to_dataset(flights_df, shuffle=False, batch_size=batch_size)\n",
    "train_ds\n",
    "# ds does not yet have any data in it\n",
    "# expects data to be piped in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 1.],\n",
       "       [27.],\n",
       "       [ 2.],\n",
       "       [68.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw data is ready, but features are not specified\n",
    "example_batch = next(iter(train_ds))[0]\n",
    "\n",
    "departure_delay = tf.feature_column.numeric_column('departure_delay')\n",
    "# creates a numeric column\n",
    "feature_layer_demo = tf.keras.layers.DenseFeatures(departure_delay)\n",
    "feature_layer_demo(example_batch).numpy()[:5]\n",
    "# calls feature layer like you would any dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departure_delay_bucketized = tf.feature_column.bucketized_column(departure_delay, boundaries=[2,3,6,9,13])\n",
    "\n",
    "feature_layer_demo = tf.keras.layers.DenseFeatures(departure_delay_bucketized)\n",
    "feature_layer_demo(example_batch).numpy()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_delay_bins = [2,3,6,9,13,19,28,44,72]\n",
    "weekday_voc = [ str(n) for n in list(range(8)) ]\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "# the following code should be made into a function to avoid repetition\n",
    "\n",
    "departure_delay = tf.feature_column.numeric_column('departure_delay')\n",
    "departure_delay_buckets = tf.feature_column.bucketized_column(departure_delay, boundaries=departure_delay_bins)\n",
    "feature_columns.append(departure_delay_buckets)\n",
    "# create bucketized feature column for a numeric value\n",
    "\n",
    "weekdays = tf.feature_column.categorical_column_with_vocabulary_list('departure_weekday', weekday_voc)\n",
    "weekday_dummy = tf.feature_column.indicator_column(weekdays)\n",
    "feature_columns.append(weekday_dummy)\n",
    "# create discretized feature column for string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 18])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer_demo = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer_demo(example_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer_demo(example_batch).numpy()[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "model_normal = tf.keras.models.Sequential([\n",
    "    feature_layer,\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "# regularizers provide \"penalties\" when training, to keep values from becoming to large or erratic\n",
    "\n",
    "# kernel regularizers are used when you don't know the distribution, shapes the WEIGHTS\n",
    "# bias regularizers are used to make the output function pass as close to the origin as possible\n",
    "# activity regularizers are used to make the output to the function chill tf out\n",
    "\n",
    "# basically avoids overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTRIBUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mirrored Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "distribute = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribute.scope():\n",
    "    # define model\n",
    "    # compile model\n",
    "    \n",
    "    # same as non-distributed\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better for large networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
